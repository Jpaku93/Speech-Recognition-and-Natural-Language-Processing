{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "# os.getcwd()\n",
    "home = os.getcwd()\n",
    "# % matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences from the text file\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text file\n",
    "os.chdir(home)\n",
    "if not os.path.exists('Translator'):\n",
    "    os.mkdir('Translator')\n",
    "os.chdir('Translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nld.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2f6413d7645e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nld.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdeu_eng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdeu_eng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeu_eng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-61ab166cfbc6>\u001b[0m in \u001b[0;36mread_text\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# open the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# read all text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nld.txt'"
     ]
    }
   ],
   "source": [
    "data_name = \"nld.txt\"\n",
    "data = read_text(data_name)\n",
    "# data\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)\n",
    "len(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Vooruit.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #7915821 (Elsofie)'],\n",
       "       ['Hi.', 'Hoi.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #537889 (Dorenda)'],\n",
       "       ['Hi.', 'HÃ©!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #6117419 (Raizin)'],\n",
       "       ['Hi.', 'Hai!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #6117420 (Raizin)']],\n",
       "      dtype='<U286')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trim and preview file\n",
    "deu_eng = deu_eng[:50000,:]\n",
    "deu_eng[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,1]:\n",
    "    deu_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize df for bar plotting\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot bar to identify a suitable sequence length\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 7487\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 10320\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "# chos sequence length is 8\n",
    "deu_length = 8\n",
    "# identify unique words\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a file to pickle tokenizers for prediction\n",
    "if not os.path.exists('Tokenizer'):\n",
    "    os.mkdir('Tokenizer')\n",
    "os.chdir('Tokenizer')\n",
    "\n",
    "# initialize a name for saving\n",
    "name = data_name.split(\".\")[0]\n",
    "\n",
    "# pickle file with the name and pickle tag\n",
    "filename = name+'_eng_tokenizer.pickle'\n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump(eng_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# pickle file with the name and pickle tag\n",
    "filename = name+'_deu_tokenizer.pickle'\n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump(deu_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training sequences\n",
    "trainX = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = encode_sequences(deu_tokenizer, deu_length, train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation sequences\n",
    "testX = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "testY = encode_sequences(deu_tokenizer, deu_length, test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model paramaters\n",
    "model = build_model(eng_vocab_size, deu_vocab_size, eng_length,deu_length, 512)\n",
    "rms = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home)\n",
    "os.chdir('Translator')\n",
    "\n",
    "if not os.path.exists('Models'):\n",
    "    os.mkdir('Models')\n",
    "os.chdir('Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date=datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.7030\n",
      "Epoch 1: val_loss improved from inf to 3.68946, saving model to present_model.h5\n",
      "63/63 [==============================] - 122s 2s/step - loss: 3.7030 - val_loss: 3.6895\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.5173\n",
      "Epoch 2: val_loss improved from 3.68946 to 3.60880, saving model to present_model.h5\n",
      "63/63 [==============================] - 126s 2s/step - loss: 3.5173 - val_loss: 3.6088\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.3789\n",
      "Epoch 3: val_loss improved from 3.60880 to 3.47148, saving model to present_model.h5\n",
      "63/63 [==============================] - 88s 1s/step - loss: 3.3789 - val_loss: 3.4715\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.2373\n",
      "Epoch 4: val_loss improved from 3.47148 to 3.33286, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 3.2373 - val_loss: 3.3329\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.0907\n",
      "Epoch 5: val_loss improved from 3.33286 to 3.24628, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 3.0907 - val_loss: 3.2463\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.9562\n",
      "Epoch 6: val_loss improved from 3.24628 to 3.15816, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 2.9562 - val_loss: 3.1582\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.8382\n",
      "Epoch 7: val_loss improved from 3.15816 to 3.06976, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 2.8382 - val_loss: 3.0698\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.7328\n",
      "Epoch 8: val_loss improved from 3.06976 to 2.97366, saving model to present_model.h5\n",
      "63/63 [==============================] - 88s 1s/step - loss: 2.7328 - val_loss: 2.9737\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.6285\n",
      "Epoch 9: val_loss improved from 2.97366 to 2.90069, saving model to present_model.h5\n",
      "63/63 [==============================] - 94s 1s/step - loss: 2.6285 - val_loss: 2.9007\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.5229\n",
      "Epoch 10: val_loss improved from 2.90069 to 2.83613, saving model to present_model.h5\n",
      "63/63 [==============================] - 92s 1s/step - loss: 2.5229 - val_loss: 2.8361\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.4151\n",
      "Epoch 11: val_loss improved from 2.83613 to 2.80715, saving model to present_model.h5\n",
      "63/63 [==============================] - 91s 1s/step - loss: 2.4151 - val_loss: 2.8071\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3070\n",
      "Epoch 12: val_loss improved from 2.80715 to 2.71647, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 2.3070 - val_loss: 2.7165\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.2009\n",
      "Epoch 13: val_loss improved from 2.71647 to 2.62051, saving model to present_model.h5\n",
      "63/63 [==============================] - 87s 1s/step - loss: 2.2009 - val_loss: 2.6205\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0967\n",
      "Epoch 14: val_loss improved from 2.62051 to 2.56781, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 2.0967 - val_loss: 2.5678\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9975\n",
      "Epoch 15: val_loss improved from 2.56781 to 2.51131, saving model to present_model.h5\n",
      "63/63 [==============================] - 84s 1s/step - loss: 1.9975 - val_loss: 2.5113\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9026\n",
      "Epoch 16: val_loss improved from 2.51131 to 2.46971, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 1.9026 - val_loss: 2.4697\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8118\n",
      "Epoch 17: val_loss improved from 2.46971 to 2.43713, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 1.8118 - val_loss: 2.4371\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7257\n",
      "Epoch 18: val_loss improved from 2.43713 to 2.35953, saving model to present_model.h5\n",
      "63/63 [==============================] - 87s 1s/step - loss: 1.7257 - val_loss: 2.3595\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6385\n",
      "Epoch 19: val_loss improved from 2.35953 to 2.34492, saving model to present_model.h5\n",
      "63/63 [==============================] - 87s 1s/step - loss: 1.6385 - val_loss: 2.3449\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5592\n",
      "Epoch 20: val_loss improved from 2.34492 to 2.28545, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 1.5592 - val_loss: 2.2854\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4772\n",
      "Epoch 21: val_loss improved from 2.28545 to 2.23935, saving model to present_model.h5\n",
      "63/63 [==============================] - 83s 1s/step - loss: 1.4772 - val_loss: 2.2394\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4053\n",
      "Epoch 22: val_loss improved from 2.23935 to 2.21386, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 1.4053 - val_loss: 2.2139\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3300\n",
      "Epoch 23: val_loss improved from 2.21386 to 2.18720, saving model to present_model.h5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 1.3300 - val_loss: 2.1872\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2609\n",
      "Epoch 24: val_loss did not improve from 2.18720\n",
      "63/63 [==============================] - 97s 2s/step - loss: 1.2609 - val_loss: 2.1949\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1914\n",
      "Epoch 25: val_loss improved from 2.18720 to 2.14522, saving model to present_model.h5\n",
      "63/63 [==============================] - 98s 2s/step - loss: 1.1914 - val_loss: 2.1452\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1294\n",
      "Epoch 26: val_loss improved from 2.14522 to 2.12874, saving model to present_model.h5\n",
      "63/63 [==============================] - 98s 2s/step - loss: 1.1294 - val_loss: 2.1287\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0685\n",
      "Epoch 27: val_loss improved from 2.12874 to 2.10671, saving model to present_model.h5\n",
      "63/63 [==============================] - 98s 2s/step - loss: 1.0685 - val_loss: 2.1067\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0089\n",
      "Epoch 28: val_loss did not improve from 2.10671\n",
      "63/63 [==============================] - 97s 2s/step - loss: 1.0089 - val_loss: 2.1085\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9536\n",
      "Epoch 29: val_loss improved from 2.10671 to 2.08645, saving model to present_model.h5\n",
      "63/63 [==============================] - 96s 2s/step - loss: 0.9536 - val_loss: 2.0865\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8994\n",
      "Epoch 30: val_loss improved from 2.08645 to 2.07187, saving model to present_model.h5\n",
      "63/63 [==============================] - 101s 2s/step - loss: 0.8994 - val_loss: 2.0719\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8504\n",
      "Epoch 31: val_loss did not improve from 2.07187\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8504 - val_loss: 2.0763\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8008\n",
      "Epoch 32: val_loss did not improve from 2.07187\n",
      "63/63 [==============================] - 98s 2s/step - loss: 0.8008 - val_loss: 2.1045\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7525\n",
      "Epoch 33: val_loss improved from 2.07187 to 2.05259, saving model to present_model.h5\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.7525 - val_loss: 2.0526\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7124\n",
      "Epoch 34: val_loss improved from 2.05259 to 2.04667, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.7124 - val_loss: 2.0467\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6695\n",
      "Epoch 35: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.6695 - val_loss: 2.0532\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6262\n",
      "Epoch 36: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.6262 - val_loss: 2.1162\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5923\n",
      "Epoch 37: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.5923 - val_loss: 2.0570\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5547\n",
      "Epoch 38: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.5547 - val_loss: 2.0763\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5207\n",
      "Epoch 39: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.5207 - val_loss: 2.0773\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4897\n",
      "Epoch 40: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 87s 1s/step - loss: 0.4897 - val_loss: 2.0775\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4582\n",
      "Epoch 41: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 89s 1s/step - loss: 0.4582 - val_loss: 2.1075\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4299\n",
      "Epoch 42: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.4299 - val_loss: 2.0959\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4060\n",
      "Epoch 43: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 115s 2s/step - loss: 0.4060 - val_loss: 2.1103\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3797\n",
      "Epoch 44: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 112s 2s/step - loss: 0.3797 - val_loss: 2.1072\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3561\n",
      "Epoch 45: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 113s 2s/step - loss: 0.3561 - val_loss: 2.1118\n",
      "Epoch 46/50\n",
      "59/63 [===========================>..] - ETA: 6s - loss: 0.3346"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-e700568156cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n\u001b[0m\u001b[0;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m           \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "filename = str(date) + 'present_model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=50, batch_size=512, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-314735a9fdda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = '2022-06-17 15:17:06.977984_ENG_TO_DEU', errno = 22, error message = 'Invalid argument', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-35b4671b1a7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_ENG_TO_DEU'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '2022-06-17 15:17:06.977984_ENG_TO_DEU', errno = 22, error message = 'Invalid argument', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "# filename = str(date) + '_ENG_TO_DEU.h5'\n",
    "# model.save(filename, save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Acer\\\\123 NLP'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testX.shape[0]\n",
    "# testX.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'present_model.h5'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 44s 126ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "os.chdir(home)\n",
    "os.chdir('Translator\\\\Models')\n",
    "model = load_model(os.listdir()[0])\n",
    "# Predict the first item in tmp_x\n",
    "prediction = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a funcction for converting logits into text\n",
    "def logits_to_text(logits, tokenizer):\n",
    "    \n",
    "    # Get index to words\n",
    "    index2word = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    \n",
    "    # Add '<PAD>' at start of index2word\n",
    "    index2word[0] = ''\n",
    "    \n",
    "    # Get the text\n",
    "    text = \" \".join([index2word[prediction] for prediction in np.argmax(logits, 1)])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the logits into text\n",
    "predicted_text = []\n",
    "for i in prediction:\n",
    "    predicted_text.append(logits_to_text(logits = i, tokenizer = deu_tokenizer))\n",
    "# print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,1], 'predicted' : predicted_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ik kon mijn eigen ogen niet geloven</td>\n",
       "      <td>ik kon mijn ogen niet geloven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lach naar het vogeltje</td>\n",
       "      <td>zeg kaas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hij haat spinnen</td>\n",
       "      <td>hij haat spinnen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meende tom het serieus</td>\n",
       "      <td>was tom tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waar bent u naar op zoek meneer</td>\n",
       "      <td>wat zoek jullie naar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tom en maria liften</td>\n",
       "      <td>tom en mary zijn van het</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>die kamer wordt als keuken gebruikt</td>\n",
       "      <td>deze kamer is een een mijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hij is bang dat hij zal sterven</td>\n",
       "      <td>hij is of hij hij moet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hij wilde slagen</td>\n",
       "      <td>hij wilde later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ik woon nog steeds in australiÃ«</td>\n",
       "      <td>ik woon nog steeds in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                actual                        predicted\n",
       "0  ik kon mijn eigen ogen niet geloven  ik kon mijn ogen niet geloven  \n",
       "1               lach naar het vogeltje                   zeg kaas      \n",
       "2                     hij haat spinnen            hij haat spinnen     \n",
       "3               meende tom het serieus                 was tom tom     \n",
       "4      waar bent u naar op zoek meneer         wat zoek jullie naar    \n",
       "5                  tom en maria liften       tom en mary zijn van het  \n",
       "6  die kamer wordt als keuken gebruikt     deze kamer is een een mijn  \n",
       "7      hij is bang dat hij zal sterven         hij is of hij hij moet  \n",
       "8                     hij wilde slagen             hij wilde later     \n",
       "9      ik woon nog steeds in australiÃ«         ik woon nog steeds in   "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>die vind ik leuker</td>\n",
       "      <td>ik vind dat dat goed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>ik heb de deur van het slot gehaald</td>\n",
       "      <td>ik deed de deur dicht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>misschien is tom niet slaperig</td>\n",
       "      <td>tom kan zijn dat niet niet slaperig is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>ik kan voor mezelf opkomen</td>\n",
       "      <td>ik spreek op op muziek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>tom kwam heel laat aan</td>\n",
       "      <td>tom is hier laat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>tom heeft de hele zak opgegeten</td>\n",
       "      <td>tom heeft de de van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>we moeten ons registreren</td>\n",
       "      <td>we hebben elkaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>was het goed</td>\n",
       "      <td>was het goed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>je was met tom aan het flirten</td>\n",
       "      <td>je bent met op tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>is dat tom zijn vrouw</td>\n",
       "      <td>is dat tom hond hond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>ik weet dat tom kleurenblind is</td>\n",
       "      <td>ik weet dat tom kleurenblind is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>ik moest het zelf doen</td>\n",
       "      <td>ik moest het op moeten doen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>tom houdt van tuinieren</td>\n",
       "      <td>tom houdt van op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>ze sprak de hele tijd</td>\n",
       "      <td>ze praatte het het tijd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>snij alsjeblieft de wortels</td>\n",
       "      <td>trek de de uit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   actual  \\\n",
       "9985                   die vind ik leuker   \n",
       "9986  ik heb de deur van het slot gehaald   \n",
       "9987       misschien is tom niet slaperig   \n",
       "9988           ik kan voor mezelf opkomen   \n",
       "9989               tom kwam heel laat aan   \n",
       "9990      tom heeft de hele zak opgegeten   \n",
       "9991            we moeten ons registreren   \n",
       "9992                         was het goed   \n",
       "9993       je was met tom aan het flirten   \n",
       "9994                is dat tom zijn vrouw   \n",
       "9995      ik weet dat tom kleurenblind is   \n",
       "9996               ik moest het zelf doen   \n",
       "9997              tom houdt van tuinieren   \n",
       "9998                ze sprak de hele tijd   \n",
       "9999          snij alsjeblieft de wortels   \n",
       "\n",
       "                                   predicted  \n",
       "9985                 ik vind dat dat goed     \n",
       "9986                ik deed de deur dicht     \n",
       "9987  tom kan zijn dat niet niet slaperig is  \n",
       "9988               ik spreek op op muziek     \n",
       "9989                    tom is hier laat      \n",
       "9990                  tom heeft de de van     \n",
       "9991                   we hebben elkaar       \n",
       "9992                       was het goed       \n",
       "9993                   je bent met op tom     \n",
       "9994                 is dat tom hond hond     \n",
       "9995       ik weet dat tom kleurenblind is    \n",
       "9996           ik moest het op moeten doen    \n",
       "9997                    tom houdt van op      \n",
       "9998              ze praatte het het tijd     \n",
       "9999                      trek de de uit      "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>die vind ik leuker</td>\n",
       "      <td>ik vind dat dat goed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>ik heb de deur van het slot gehaald</td>\n",
       "      <td>ik deed de deur dicht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>misschien is tom niet slaperig</td>\n",
       "      <td>tom kan zijn dat niet niet slaperig is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>ik kan voor mezelf opkomen</td>\n",
       "      <td>ik spreek op op muziek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>tom kwam heel laat aan</td>\n",
       "      <td>tom is hier laat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>tom heeft de hele zak opgegeten</td>\n",
       "      <td>tom heeft de de van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>we moeten ons registreren</td>\n",
       "      <td>we hebben elkaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>was het goed</td>\n",
       "      <td>was het goed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>je was met tom aan het flirten</td>\n",
       "      <td>je bent met op tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>is dat tom zijn vrouw</td>\n",
       "      <td>is dat tom hond hond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>ik weet dat tom kleurenblind is</td>\n",
       "      <td>ik weet dat tom kleurenblind is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>ik moest het zelf doen</td>\n",
       "      <td>ik moest het op moeten doen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>tom houdt van tuinieren</td>\n",
       "      <td>tom houdt van op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>ze sprak de hele tijd</td>\n",
       "      <td>ze praatte het het tijd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>snij alsjeblieft de wortels</td>\n",
       "      <td>trek de de uit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   actual  \\\n",
       "9985                   die vind ik leuker   \n",
       "9986  ik heb de deur van het slot gehaald   \n",
       "9987       misschien is tom niet slaperig   \n",
       "9988           ik kan voor mezelf opkomen   \n",
       "9989               tom kwam heel laat aan   \n",
       "9990      tom heeft de hele zak opgegeten   \n",
       "9991            we moeten ons registreren   \n",
       "9992                         was het goed   \n",
       "9993       je was met tom aan het flirten   \n",
       "9994                is dat tom zijn vrouw   \n",
       "9995      ik weet dat tom kleurenblind is   \n",
       "9996               ik moest het zelf doen   \n",
       "9997              tom houdt van tuinieren   \n",
       "9998                ze sprak de hele tijd   \n",
       "9999          snij alsjeblieft de wortels   \n",
       "\n",
       "                                   predicted  \n",
       "9985                 ik vind dat dat goed     \n",
       "9986                ik deed de deur dicht     \n",
       "9987  tom kan zijn dat niet niet slaperig is  \n",
       "9988               ik spreek op op muziek     \n",
       "9989                    tom is hier laat      \n",
       "9990                  tom heeft de de van     \n",
       "9991                   we hebben elkaar       \n",
       "9992                       was het goed       \n",
       "9993                   je bent met op tom     \n",
       "9994                 is dat tom hond hond     \n",
       "9995       ik weet dat tom kleurenblind is    \n",
       "9996           ik moest het op moeten doen    \n",
       "9997                    tom houdt van op      \n",
       "9998              ze praatte het het tijd     \n",
       "9999                      trek de de uit      "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>ik ben er zeker van dat we veel gemeen hebben</td>\n",
       "      <td>ik weet niet veel veel veel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>ze verkoopt groenten</td>\n",
       "      <td>ze verkoopt groentes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>hij kan ieder moment terug zijn</td>\n",
       "      <td>hij zou hier zijn zijn zijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>laten we naar het strand gaan</td>\n",
       "      <td>laten we naar het strand gaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>de hitte is overweldigend</td>\n",
       "      <td>de maan is aan  tikken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182</th>\n",
       "      <td>we moeten een plan hebben</td>\n",
       "      <td>we moeten een plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8651</th>\n",
       "      <td>hij weet wie we zijn</td>\n",
       "      <td>hij weet wie wie zijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>laten we niet gaan</td>\n",
       "      <td>laten we niet niet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>hoeveel kostte dat bier</td>\n",
       "      <td>hoeveel kost deze stropdas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>ik heb nooit van je gehouden</td>\n",
       "      <td>ik heb nooit van je gehouden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>ik heb een geweldig leven</td>\n",
       "      <td>ik heb een nieuw leven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8543</th>\n",
       "      <td>er zijn parkeerplaatsen voor invaliden beschikbaar</td>\n",
       "      <td>er is een invalidenparkeerplaats beschikbaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>laat ons versterking vragen</td>\n",
       "      <td>laten we een kijkje nemen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>met jullie wil ik oud worden</td>\n",
       "      <td>ik wil met met met jij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>is er een oplossing gevonden</td>\n",
       "      <td>is een een klasgenoten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  actual  \\\n",
       "7330       ik ben er zeker van dat we veel gemeen hebben   \n",
       "3335                                ze verkoopt groenten   \n",
       "5312                     hij kan ieder moment terug zijn   \n",
       "4083                       laten we naar het strand gaan   \n",
       "5750                           de hitte is overweldigend   \n",
       "7182                           we moeten een plan hebben   \n",
       "8651                                hij weet wie we zijn   \n",
       "8973                                  laten we niet gaan   \n",
       "5986                             hoeveel kostte dat bier   \n",
       "335                         ik heb nooit van je gehouden   \n",
       "1563                           ik heb een geweldig leven   \n",
       "8543  er zijn parkeerplaatsen voor invaliden beschikbaar   \n",
       "4040                         laat ons versterking vragen   \n",
       "5823                        met jullie wil ik oud worden   \n",
       "2262                        is er een oplossing gevonden   \n",
       "\n",
       "                                            predicted  \n",
       "7330                    ik weet niet veel veel veel    \n",
       "3335                        ze verkoopt groentes       \n",
       "5312                    hij zou hier zijn zijn zijn    \n",
       "4083                  laten we naar het strand gaan    \n",
       "5750                         de maan is aan  tikken    \n",
       "7182                           we moeten een plan      \n",
       "8651                         hij weet wie wie zijn     \n",
       "8973                           laten we niet niet      \n",
       "5986                   hoeveel kost deze stropdas      \n",
       "335                    ik heb nooit van je gehouden    \n",
       "1563                        ik heb een nieuw leven     \n",
       "8543  er is een invalidenparkeerplaats beschikbaar     \n",
       "4040                     laten we een kijkje nemen     \n",
       "5823                         ik wil met met met jij    \n",
       "2262                       is een een klasgenoten      "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['its time to pack up', 'het is tijd om in te pakken',\n",
       "       'CC-BY 2.0 (France) Attribution: tatoeba.org #7913357 (CK) & #7928755 (MarijnKp)'],\n",
       "      dtype='<U286')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[8174]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'its time to pack up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "querye = query[0].translate(str.maketrans('', '', string.punctuation))\n",
    "encoded_query = encode_sequences(eng_tokenizer, eng_length, querye)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prob = model.predict(encoded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the logits into text\n",
    "predicted_text = []\n",
    "for i in prob:\n",
    "    predicted_text.append(logits_to_text(logits = i, tokenizer = deu_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten\n"
     ]
    }
   ],
   "source": [
    "print(predicted_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : query, 'predicted' : predicted_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>in zit de de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>een</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>het</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>in zit de de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 actual  \\\n",
       "0   its time to pack up   \n",
       "1   its time to pack up   \n",
       "2   its time to pack up   \n",
       "3   its time to pack up   \n",
       "4   its time to pack up   \n",
       "5   its time to pack up   \n",
       "6   its time to pack up   \n",
       "7   its time to pack up   \n",
       "8   its time to pack up   \n",
       "9   its time to pack up   \n",
       "10  its time to pack up   \n",
       "11  its time to pack up   \n",
       "12  its time to pack up   \n",
       "13  its time to pack up   \n",
       "14  its time to pack up   \n",
       "15  its time to pack up   \n",
       "16  its time to pack up   \n",
       "17  its time to pack up   \n",
       "18  its time to pack up   \n",
       "\n",
       "                                                         predicted  \n",
       "0   ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten  \n",
       "1                                                                   \n",
       "2                                                                   \n",
       "3                                                                   \n",
       "4                                                                   \n",
       "5   ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten  \n",
       "6                                                                   \n",
       "7                                                                   \n",
       "8                                                                   \n",
       "9                                                                   \n",
       "10                                                                  \n",
       "11                                                                  \n",
       "12                                                in zit de de      \n",
       "13                                                      een         \n",
       "14                                                      het         \n",
       "15                                                                  \n",
       "16                                                                  \n",
       "17                                                                  \n",
       "18                                                in zit de de      "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "couldnt work it out but it seemed to do fine with a data set so with the dataset of notes theat ive made il throw through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
